{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent\n",
    "## The vector of partial derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.vector_type import Vector\n",
    "from common.dot import dot\n",
    "\n",
    "def sum_of_squares(v: Vector) -> float:\n",
    "    \"\"\"Computes the sum of squared elements in v\"\"\"\n",
    "    return dot(v, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating the Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "def difference_quotient(f: Callable[[float], float],\n",
    "                        x: float,\n",
    "                        h: float) -> float:\n",
    "    return (f(x + h) - f(x)) / h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square(x: float) -> float:\n",
    "    return x * x\n",
    "\n",
    "def derivative(x: float) -> float:\n",
    "    return 2 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = range(-10, 11)\n",
    "actuals = [derivative(x) for x in xs]\n",
    "estimates = [difference_quotient(square, x, h=0.001) for x in xs]\n",
    "# plot to show they're basically the same\n",
    "import matplotlib.pyplot as plt \n",
    "plt.title(\"Actual Derivatives vs. Estimates\") \n",
    "plt.plot(xs, actuals, 'rx', label='Actual') \n",
    "plt.plot(xs, estimates, 'b+', label='Estimate') \n",
    "plt.legend(loc=9)\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "plt.savefig('image/img014.png')\n",
    "plt.gca().clear()\n",
    "plt.close()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_difference_quotient(f: Callable[[Vector], float],\n",
    "                                v: Vector,\n",
    "                                i: int,\n",
    "                                h: float) -> float:\n",
    "    \"\"\"Returns the i-th partial difference quotient of f at v\"\"\"\n",
    "    w = [v_j + (h if j == i else 0)    # add h to just the ith element of v\n",
    "            for j, v_j in enumerate(v)]\n",
    "    return (f(w) - f(v)) / h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_gradient(f: Callable[[Vector], float],\n",
    "                      v: Vector,\n",
    "                      h: float = 0.0001):\n",
    "    return [partial_difference_quotient(f, v, i, h)\n",
    "            for i in range(len(v))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from common.add import add\n",
    "from common.distance import distance\n",
    "from common.scalar_multiply import scalar_multiply\n",
    "from common.vector_type import Vector\n",
    "\n",
    "def gradient_step(v: Vector, gradient: Vector, step_size: float) -> Vector:\n",
    "    \"\"\"Moves `step_size` in the `gradient` direction from `v`\"\"\"\n",
    "    assert len(v) == len(gradient)\n",
    "    step = scalar_multiply(step_size, gradient)\n",
    "    return add(v, step)\n",
    "\n",
    "def sum_of_squares_gradient(v: Vector) -> Vector:\n",
    "    return [2 * v_i for v_i in v]\n",
    "\n",
    "v = [random.uniform(-10, 10) for i in range(3)]\n",
    "\n",
    "for epoch in range(1000):\n",
    "    grad = sum_of_squares_gradient(v)\n",
    "    v = gradient_step(v, grad, -0.01)\n",
    "    print(epoch, v)\n",
    "\n",
    "assert distance(v, [0, 0, 0]) < 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Gradient Descent to Fit Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x ranges from -50 to 49, y is always 20 * x + 5\n",
    "inputs = [(x, 20 * x + 5) for x in range(-50, 50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_gradient(x: float, y: float, theta: Vector) -> Vector:\n",
    "    slope, intercept = theta\n",
    "    predicted = slope * x + intercept    # The prediction of the model.\n",
    "    error = (predicted - y)              # error is (predicted - actual)\n",
    "    squared_error = error ** 2           # We'll minimize squared error\n",
    "    grad = [2 * error * x, 2 * error]    # using its gradient.\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.vector_mean import vector_mean\n",
    "\n",
    "# Start with random values for slope and intercept.\n",
    "theta = [random.uniform(-1, 1), random.uniform(-1, 1)]\n",
    "\n",
    "learning_rate = 0.001\n",
    "\n",
    "for epoch in range(5000):\n",
    "    # Compute the mean of the gradients\n",
    "    grad = vector_mean([linear_gradient(x, y, theta) for x, y in inputs])\n",
    "    # Take a step in that direction\n",
    "    theta = gradient_step(theta, grad, -learning_rate)\n",
    "    print(epoch, theta)\n",
    "\n",
    "slope, intercept = theta\n",
    "assert 19.9 < slope < 20.1,   \"slope should be about 20\"\n",
    "assert 4.9 < intercept < 5.1, \"intercept should be about 5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minibatch and Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypeVar, List, Iterator\n",
    "\n",
    "T = TypeVar('T')  # this allows us to type \"generic\" functions\n",
    "\n",
    "def minibatches(dataset: List[T],\n",
    "                batch_size: int,\n",
    "                shuffle: bool = True) -> Iterator[List[T]]:\n",
    "    \"\"\"Generates `batch_size`-sized minibatches from the dataset\"\"\"\n",
    "    # Start indexes 0, batch_size, 2 * batch_size, ...\n",
    "    batch_starts = [start for start in range(0, len(dataset), batch_size)]\n",
    "    if shuffle: random.shuffle(batch_starts)  # shuffle the batches\n",
    "    for start in batch_starts:\n",
    "        end = start + batch_size\n",
    "        yield dataset[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = [random.uniform(-1, 1), random.uniform(-1, 1)]\n",
    "\n",
    "for epoch in range(1000):\n",
    "    for batch in minibatches(inputs, batch_size=20):\n",
    "        grad = vector_mean([linear_gradient(x, y, theta) for x, y in batch])\n",
    "        theta = gradient_step(theta, grad, -learning_rate)\n",
    "    print(epoch, theta)\n",
    "\n",
    "slope, intercept = theta\n",
    "assert 19.9 < slope < 20.1,   \"slope should be about 20\"\n",
    "assert 4.9 < intercept < 5.1, \"intercept should be about 5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = [random.uniform(-1, 1), random.uniform(-1, 1)]\n",
    "\n",
    "for epoch in range(100):\n",
    "    for x, y in inputs:\n",
    "        grad = linear_gradient(x, y, theta)\n",
    "        theta = gradient_step(theta, grad, -learning_rate)\n",
    "    print(epoch, theta)\n",
    "\n",
    "slope, intercept = theta\n",
    "assert 19.9 < slope < 20.1,   \"slope should be about 20\"\n",
    "assert 4.9 < intercept < 5.1, \"intercept should be about 5\""
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "580334040f56039d3caacea6cc9b85b0f989c2f977ea3f5715f6ed60c64ca9a7"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
